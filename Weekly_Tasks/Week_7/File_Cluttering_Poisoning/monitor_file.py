import os
import time
import hashlib
import logging
import ctypes

def hash_file(file_path):
    # Generate a hash of the file content (using SHA256)
    sha256 = hashlib.sha256()
    with open(file_path, "rb") as file:
        for chunk in iter(lambda: file.read(4096), b""):
            sha256.update(chunk)
    return sha256.hexdigest()

def monitor_directory(directory, log_file, max_files_per_interval=10, interval=10):
    file_states = {}

    # Setup logging configuration
    logging.basicConfig(filename=log_file, level=logging.INFO,
                        format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

    while True:
        new_files_counter = 0

        for root, _, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    # Get the file's current hash
                    current_hash = hash_file(file_path)

                    # If the file is new or its content has changed
                    if file_path not in file_states or file_states[file_path] != current_hash:
                        if file_path not in file_states:
                            event = "NEW FILE"
                            new_files_counter += 1
                        else:
                            event = "FILE MODIFIED"
                        file_states[file_path] = current_hash

                        # Log the event with the timestamp
                        logging.info(f"{event} - File: {file_path}")

                        # Show real-time output
                        print(f"{event} - File: {file_path}")

                except Exception as e:
                    print(f"Error accessing {file_path}: {e}")

        # Check for deleted files and log the event
        for file_path in list(file_states.keys()):
            if not os.path.exists(file_path):
                logging.info(f"FILE DELETED - File: {file_path}")
                del file_states[file_path]

                # Show real-time output
                print(f"FILE DELETED - File: {file_path}")

        # Check for excessive file creation or download activity
        if new_files_counter >= max_files_per_interval:
            logging.warning(f"WARNING: Excessive file creation or download activity detected. {new_files_counter} new files created within {interval} seconds.")
            print(f"WARNING: Excessive file creation or download activity detected. {new_files_counter} new files created within {interval} seconds.")
            # Add your code to take appropriate action here, e.g., stop the activity or notify an administrator.

        # Wait for the specified interval before checking the directory again
        time.sleep(interval)

if __name__ == "__main__":
    target_directory = "D:\\Files\\Week9\\File_Cluttering_Poisoning"  # Change this to the directory you want to monitor
    log_file = "D:\\Files\\Week9\\logs\\file_activity_log.log"  # Change this to the desired log file path

    # Set proper file permissions to limit access to the log file
    os.umask(0o077)

    # Check for elevated privileges on Windows
    if os.name == 'nt' and not ctypes.windll.shell32.IsUserAnAdmin():
        print("This script requires elevated privileges. Please run as an administrator.")
        exit(1)

    # Start monitoring the directory with file integrity checking and activity detection
    print(f"Monitoring directory: {target_directory}")
    monitor_directory(target_directory, log_file)

